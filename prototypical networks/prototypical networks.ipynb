{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python37664bit23e172fc09fa4a009286131809a53f15",
      "display_name": "Python 3.7.6 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "metadata": {
      "interpreter": {
        "hash": "c2bb4c3659b3800c6f5c337833d4b61a13da9254187e1e335ac6d827c94feba0"
      }
    },
    "colab": {
      "name": "Prototypical_Resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUzbQy4GZX-k",
        "outputId": "a92e8c11-a745-47c7-85cd-2f6b3fcabb67"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import copy\n",
        "import numpy as np\n",
        "from numpy import *\n",
        "import pandas as pd\n",
        "pd.options.display.max_columns = None\n",
        "import pickle\n",
        "import time\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tqdm.notebook as tq\n",
        "import csv\n",
        "\n",
        "#Plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Random\n",
        "import random\n",
        "from random import choice\n",
        "from random import shuffle\n",
        "\n",
        "#Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models \n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch import optim\n",
        "import torch.autograd as autograd\n",
        "from PIL import Image\n",
        "\n",
        "#Dim reduction\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "#Livelossplot\n",
        "!pip install livelossplot --quiet\n",
        "from livelossplot import PlotLosses\n",
        "\n",
        "# get the label of the image of Versace\n",
        "def path_to_label(path):\n",
        "    path = path.split('/')\n",
        "    pre_path_num = 3\n",
        "    #label = path[pre_path_num+3] + '-' + path[pre_path_num+4] +  '-' + path[pre_path_num+5] +  '-' + path[-3] + '-' + path[-2]\n",
        "    label = path[-6] +  '-' + path[-5] +  '-' + path[-4] + '-'+ path[-3] + '-' + path[-2]\n",
        "    return label\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmcGn11zZ5nj",
        "outputId": "81991dc8-31fc-4127-9d73-8dc3d14a3b28"
      },
      "source": [
        "# connect the google drive \n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfcBB7zwfRWZ"
      },
      "source": [
        "# !unzip -u \"/content/drive/MyDrive/PoleS8/few_shot_learning_brands.zip\" -d \"/content/drive/My Drive/PoleS8/Brands\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey64T11gZX-n"
      },
      "source": [
        "# read data \n",
        "train_df = pd.read_csv('/content/drive/MyDrive/PoleS8/train_100_categories.csv')\n",
        "support_df = pd.read_csv('/content/drive/MyDrive/PoleS8/support_50_categories.csv')\n",
        "query_df = pd.read_csv('/content/drive/MyDrive/PoleS8/query_50_categories.csv')\n",
        "\n",
        "\n",
        "def set_path_replace(set_df):\n",
        "  set_df.path = set_df.path.apply(lambda x:x.replace('/content/drive/MyDrive/','/content/drive/MyDrive/PoleS8/Brands/'))\n",
        "\n",
        "set_path_replace(train_df)\n",
        "set_path_replace(support_df)\n",
        "set_path_replace(query_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gNHcFNNZX-p"
      },
      "source": [
        "def enforce_all_seeds(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "    rgen = np.random.default_rng(seed)\n",
        "    return rgen\n",
        "\n",
        "rgen = enforce_all_seeds(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2lg45m8ZX-p"
      },
      "source": [
        "# ResNet50 network\n",
        "class ResNet50(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ResNet50, self).__init__()\n",
        "        \n",
        "        # importing ResNet50 and freezing all weights\n",
        "        model = models.resnet50(pretrained=True)\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "            \n",
        "        # remove the last fully connected layers of ResNet50\n",
        "        model.fc = nn.Sequential()\n",
        "        self.conv = model\n",
        "        \n",
        "        # redifine the fully connected network\n",
        "        self.fc1 = nn.Linear(2048,1024)\n",
        "        self.fc2 = nn.Linear(1024,512)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.sigmoid(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfbjvWS5ZX-q"
      },
      "source": [
        "# Prototypical network\n",
        "'''\n",
        "- df_paths_labels: the train dataframe of Versace\n",
        "- support_df: the support dataframe of Versace\n",
        "- query_df: the query dataframe of Versace\n",
        "- Nc: the number of chosen categories for one episode\n",
        "- Ns: the number of categories of support set\n",
        "- Nq: the number of categories of query set\n",
        "- step: save the model every step \n",
        "- learning_rate: the learning rate\n",
        "- chosen_labels: the unique labels of Versace\n",
        "- transfor: perform some operation on image\n",
        "- trainval: load the model if True\n",
        "'''\n",
        "class Prototypical(Dataset):\n",
        "    \n",
        "    def __init__(self, df_paths_labels, support_df, query_df, length, Nc, Ns, Nq, step, learning_rate, chosen_labels=None, transform=None, trainval=False):\n",
        "        self.df = df_paths_labels\n",
        "        self.len_df = len(df_paths_labels)\n",
        "        self.support_df = support_df\n",
        "        self.query_df = query_df\n",
        "        if chosen_labels is not None:\n",
        "            self.chosen_labels = chosen_labels\n",
        "        else:\n",
        "            self.chosen_labels = df_paths_labels.label.unique()\n",
        "        self.class_number = len(self.chosen_labels)\n",
        "        self.length = length\n",
        "        self.transform = transform\n",
        "        self.Ns = Ns\n",
        "        self.Nq = Nq\n",
        "        self.Nc = Nc\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        if trainval == False:\n",
        "            # initiate the Resnet50 network and the center of prototypical network \n",
        "            self.center = {}\n",
        "            self.model = ResNet50().to(device)\n",
        "        else:\n",
        "            # load the the Resnet50 network and the center of prototypical network \n",
        "            self.center = {}\n",
        "            # modify and save the file name of the model\n",
        "            self.model = torch.load('/content/drive/MyDrive/PoleS8/log/model_net_'+str(step)+'.pkl')\n",
        "            # modify the file name of the storage center\t\n",
        "            self.load_center('/content/drive/MyDrive/PoleS8/log/model_center_'+str(step)+'.csv')\t\n",
        "\n",
        "    # get the support set and query set randomly\n",
        "    def randomSample(self):\n",
        "        choose_class_labels = self.chosen_labels[:self.Nc]\n",
        "        sup_set = {}\n",
        "        que_set = {}\n",
        "        for label in choose_class_labels:\n",
        "            l = []\n",
        "            l.append(label)\n",
        "            label_path = random.choice(self.df.loc[self.df.label.isin(l)].path.values)\n",
        "            label_path_modified = path_to_label(label_path)\n",
        "            label_paths = self.df.loc[(self.df.label == label_path_modified)].path.values\n",
        "            random.shuffle(label_paths)\n",
        "            sup_set[label_path_modified] = label_paths[:self.Ns]\n",
        "            que_set[label_path_modified] =  label_paths[self.Ns:(self.Ns+self.Nq)]\n",
        "        return sup_set,que_set\n",
        "    \n",
        "    # get the feature of image using Resnet50 network\n",
        "    def getFeature(self,img_path):\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "            img = img.to(device)\n",
        "            \n",
        "        feature = self.model(img.unsqueeze(0).to(device))\n",
        "        return feature\n",
        "    \n",
        "    # compute the center of support set for one category\n",
        "    def computeCenter(self,sup_set):\n",
        "        for label, img_paths in sup_set.items():\n",
        "            feature = torch.FloatTensor(np.array([np.zeros(512)])).to(device)\n",
        "            for img_path in img_paths:\n",
        "                img_path = self.df.loc[(self.df.path == img_path)].path.values[0]\n",
        "                feature += self.getFeature(img_path)\n",
        "            self.center[label] = feature/self.Ns\n",
        "\n",
        "    # compute the distance of two cneters\n",
        "    def eucli_tensor(self,x,y):\n",
        "        return torch.sqrt(torch.sum((x-y)*(x-y))).to(device)\n",
        "    \n",
        "    # compute the loss\n",
        "    def loss(self,que_set):\n",
        "        loss_train = autograd.Variable(torch.FloatTensor([0])).to(device)\n",
        "        for label, img_paths in que_set.items():\n",
        "            for img_path in img_paths:\n",
        "                img_path = self.df.loc[(self.df.path == img_path)].path.values[0]\n",
        "                feature = self.getFeature(img_path)\n",
        "                sum = torch.FloatTensor([0]).to(device)\n",
        "                for label_center, feature_center in self.center.items():\n",
        "                    if(label != label_center):\n",
        "                        sum += torch.exp(-1*self.eucli_tensor(feature, feature_center))\n",
        "                loss_train += (self.eucli_tensor(feature, self.center[label]) + torch.log(sum))/(self.Nc * self.Nq)        \n",
        "        return loss_train\n",
        "    \n",
        "    # save centers\n",
        "    def save_center(self,path):\n",
        "        datas = []\n",
        "        for label in self.center.keys():\n",
        "            datas.append([label] + list(self.center[label].detach().cpu().numpy()))\n",
        "        with open(path,\"w\", newline=\"\") as datacsv:\n",
        "            csvwriter = csv.writer(datacsv,dialect = (\"excel\"))\n",
        "            csvwriter.writerows(datas)\n",
        "\n",
        "    # load centers\n",
        "    def load_center(self,path):\n",
        "        csvReader = csv.reader(open(path))\n",
        "        for line in csvReader:\n",
        "            label = int(line[0])\n",
        "            center = [ float(line[i]) for i in range(1,len(line))]\n",
        "            center = np.array(center)\n",
        "            center = Variable(torch.from_numpy(center))\n",
        "            self.center[label] = center\n",
        "\n",
        "    # train the Prototypical network           \n",
        "    def train(self):\n",
        "        sup_set, que_set = self.randomSample()\n",
        "        self.computeCenter(sup_set)\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(),lr=self.learning_rate) \n",
        "        optimizer.zero_grad() \n",
        "        loss_train = self.loss(que_set)\n",
        "        loss_train = loss_train.requires_grad_()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    # compute the mean avarage precision\n",
        "    def mean_average_precision(self):\n",
        "    \n",
        "        def preprocess(path):\n",
        "            transformer = transforms.Compose([transforms.Resize((256, 256)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "            return transformer(Image.open(path).convert(\"RGB\"))\n",
        "\n",
        "        def forward_pass(path):\n",
        "            img = preprocess(path)\n",
        "            y = self.model(img.unsqueeze(0).to(device))\n",
        "            y = y.detach().cpu().numpy()\n",
        "            return y\n",
        "\n",
        "        self.support_df['embedded_images'] = self.support_df.path.apply(lambda x:forward_pass(x))\n",
        "        self.query_df['embedded_images'] = self.query_df.path.apply(lambda x:forward_pass(x))\n",
        "\n",
        "        def calculate_AP(label):\n",
        "            # calculates AP for the given label\n",
        "            y_ground = self.support_df.label.apply(lambda x: 1 if x==label else 0).values\n",
        "            img_embedded = self.query_df.embedded_images.loc[self.query_df.label == label].values[0]\n",
        "            def distance_to_query(x):\n",
        "                return -np.linalg.norm(x-img_embedded)\n",
        "            y_distances = self.support_df.embedded_images.apply(lambda x: distance_to_query(x))\n",
        "            return average_precision_score(y_ground, y_distances)\n",
        "\n",
        "        # compute the mAP of query set\n",
        "        self.query_df['AP'] = self.query_df.label.apply(lambda x:calculate_AP(x))\n",
        "        mAP = np.mean(self.query_df['AP'].values)\n",
        "\n",
        "        return mAP\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RagPd15ZX-u",
        "outputId": "e2b1ae8e-3089-413c-92f2-ed1b97b39e14"
      },
      "source": [
        "# define the transformer\n",
        "transformer = transforms.Compose([transforms.Resize((256, 256)),\n",
        "                                  transforms.RandomHorizontalFlip(),\n",
        "                                  transforms.RandomRotation(10),\n",
        "                                  transforms.RandomCrop(256),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "# initiate the Prototypical network\n",
        "protonets = Prototypical(df_paths_labels=train_df, support_df=support_df, query_df=query_df, length=5000, Nc=60, Ns=5, Nq=5, step=60, learning_rate=0.0001, chosen_labels=None, transform=transformer, trainval=False)\n",
        "\n",
        "# train the Prototypical network\n",
        "for n in range(1000):\n",
        "    protonets.train()\n",
        "    # save the model and centers every 50 times\n",
        "    if n%50 ==0 and n!=0:\n",
        "         torch.save(protonets.model, '/content/drive/MyDrive/PoleS8/log/model_net_'+str(n)+'.pkl')\n",
        "         protonets.save_center('/content/drive/MyDrive/PoleS8/log/model_center_'+str(n)+'.csv')\n",
        "    map = protonets.mean_average_precision()\n",
        "    print(map)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24738492518125682\n",
            "0.24947924938227475\n",
            "0.24972491737592115\n",
            "0.25328205995481523\n",
            "0.24306394237599335\n",
            "0.2434391340196522\n",
            "0.23315662065614606\n",
            "0.22688728579675907\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}